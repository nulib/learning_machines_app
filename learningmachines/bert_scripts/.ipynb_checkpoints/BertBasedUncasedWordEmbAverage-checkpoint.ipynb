{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d42dc25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9d16438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Care_review_full.csv',\n",
       " 'pubmed_1k.json',\n",
       " 'test_pca.json',\n",
       " 'Care_Reviews_10k.json',\n",
       " 'BertBasedUncasedWordEmbAverage.ipynb',\n",
       " 'test.csv',\n",
       " 'test_cleaned.csv',\n",
       " 'test_lda.csv',\n",
       " 'bert_viz_phase2.ipynb',\n",
       " 'news_50k_cleaned.csv',\n",
       " 'news_50k_test_lda.csv',\n",
       " '.ipynb_checkpoints',\n",
       " 'news_50k_test_embs.json',\n",
       " 'news_50k_test.csv',\n",
       " 'news_50k.json',\n",
       " 'bert_viz_phase2-Copy3.ipynb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce7fb5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>data_string</th>\n",
       "      <th>2d_coor</th>\n",
       "      <th>data_title</th>\n",
       "      <th>data_category</th>\n",
       "      <th>data_category_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a224545f-1a07-47eb-96ee-a0d0cab23100</td>\n",
       "      <td>Good place to visit</td>\n",
       "      <td></td>\n",
       "      <td>urgentCare: Access Urgent Medical Care Pickeri...</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01a8cfc8-e207-4c72-a9fa-fa6353fde529</td>\n",
       "      <td>Went here for a swollen Jaw. Even though I was...</td>\n",
       "      <td></td>\n",
       "      <td>urgentCare: Access Urgent Medical Care Pickeri...</td>\n",
       "      <td>Poor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a4fb4a6-6c56-4610-a151-b4b25a774cc8</td>\n",
       "      <td>I was seen relatively quickly and the staff wa...</td>\n",
       "      <td></td>\n",
       "      <td>urgentCare: Access Urgent Medical Care Pickeri...</td>\n",
       "      <td>Excelent</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9356a4fd-54fd-4604-a6a8-2d3067eba7cc</td>\n",
       "      <td>Reception and service couldn't have been more ...</td>\n",
       "      <td></td>\n",
       "      <td>urgentCare: Access Urgent Medical Care Pickeri...</td>\n",
       "      <td>Excelent</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77526eed-5ff3-4f2f-80ce-da1048137cf4</td>\n",
       "      <td>I came in they were very busy the receptionist...</td>\n",
       "      <td></td>\n",
       "      <td>urgentCare: Access Urgent Medical Care Pickeri...</td>\n",
       "      <td>Excelent</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0669d71c-f596-4183-a6ef-6ceb660cac3f</td>\n",
       "      <td>I needed a prescription and thought going to t...</td>\n",
       "      <td></td>\n",
       "      <td>urgentCare: Cleveland Clinic Express Care Clinic</td>\n",
       "      <td>Poor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>7a73d727-b0eb-48e2-8c01-b6faf07ea776</td>\n",
       "      <td>Excellent, friendly staff. Got me in and out i...</td>\n",
       "      <td></td>\n",
       "      <td>urgentCare: CareFirst Urgent Care - Kenwood</td>\n",
       "      <td>Excelent</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>baf90288-9dc4-4de4-9b8f-f31322f48747</td>\n",
       "      <td>Awesome staff!!</td>\n",
       "      <td></td>\n",
       "      <td>urgentCare: CareFirst Urgent Care - Kenwood</td>\n",
       "      <td>Excelent</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>672cf0b1-0bc6-45aa-be18-b80d196870f7</td>\n",
       "      <td>I'm really glad that CareFirst open this facil...</td>\n",
       "      <td></td>\n",
       "      <td>urgentCare: CareFirst Urgent Care - Kenwood</td>\n",
       "      <td>Excelent</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>26cd97c2-0fea-416a-b5bc-230e8e5daa25</td>\n",
       "      <td>Staff were great and polite</td>\n",
       "      <td></td>\n",
       "      <td>urgentCare: CareFirst Urgent Care - Kenwood</td>\n",
       "      <td>Excelent</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   data_id  \\\n",
       "0     a224545f-1a07-47eb-96ee-a0d0cab23100   \n",
       "1     01a8cfc8-e207-4c72-a9fa-fa6353fde529   \n",
       "2     1a4fb4a6-6c56-4610-a151-b4b25a774cc8   \n",
       "3     9356a4fd-54fd-4604-a6a8-2d3067eba7cc   \n",
       "4     77526eed-5ff3-4f2f-80ce-da1048137cf4   \n",
       "...                                    ...   \n",
       "9995  0669d71c-f596-4183-a6ef-6ceb660cac3f   \n",
       "9996  7a73d727-b0eb-48e2-8c01-b6faf07ea776   \n",
       "9997  baf90288-9dc4-4de4-9b8f-f31322f48747   \n",
       "9998  672cf0b1-0bc6-45aa-be18-b80d196870f7   \n",
       "9999  26cd97c2-0fea-416a-b5bc-230e8e5daa25   \n",
       "\n",
       "                                            data_string 2d_coor  \\\n",
       "0                                   Good place to visit           \n",
       "1     Went here for a swollen Jaw. Even though I was...           \n",
       "2     I was seen relatively quickly and the staff wa...           \n",
       "3     Reception and service couldn't have been more ...           \n",
       "4     I came in they were very busy the receptionist...           \n",
       "...                                                 ...     ...   \n",
       "9995  I needed a prescription and thought going to t...           \n",
       "9996  Excellent, friendly staff. Got me in and out i...           \n",
       "9997                                    Awesome staff!!           \n",
       "9998  I'm really glad that CareFirst open this facil...           \n",
       "9999                        Staff were great and polite           \n",
       "\n",
       "                                             data_title data_category  \\\n",
       "0     urgentCare: Access Urgent Medical Care Pickeri...     Very Good   \n",
       "1     urgentCare: Access Urgent Medical Care Pickeri...          Poor   \n",
       "2     urgentCare: Access Urgent Medical Care Pickeri...      Excelent   \n",
       "3     urgentCare: Access Urgent Medical Care Pickeri...      Excelent   \n",
       "4     urgentCare: Access Urgent Medical Care Pickeri...      Excelent   \n",
       "...                                                 ...           ...   \n",
       "9995   urgentCare: Cleveland Clinic Express Care Clinic          Poor   \n",
       "9996        urgentCare: CareFirst Urgent Care - Kenwood      Excelent   \n",
       "9997        urgentCare: CareFirst Urgent Care - Kenwood      Excelent   \n",
       "9998        urgentCare: CareFirst Urgent Care - Kenwood      Excelent   \n",
       "9999        urgentCare: CareFirst Urgent Care - Kenwood      Excelent   \n",
       "\n",
       "     data_category_number  \n",
       "0                       4  \n",
       "1                       1  \n",
       "2                       5  \n",
       "3                       5  \n",
       "4                       5  \n",
       "...                   ...  \n",
       "9995                    1  \n",
       "9996                    5  \n",
       "9997                    5  \n",
       "9998                    5  \n",
       "9999                    5  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert .json to .csv\n",
    "# Adds the required columns with reindexing\n",
    "# Adds data category based on rating in data title\n",
    "\n",
    "import pandas as pd\n",
    "with open('Care_Reviews_10k.json', encoding='utf-8') as inputfile:\n",
    "    df = pd.read_json(inputfile)\n",
    "df\n",
    "df = df.drop(columns=[1,3,4,6])\n",
    "df = df.rename(columns={0:'data_id', 2:'data_title', 5:'data_string'})\n",
    "\n",
    "df['2d_coor'] = ''\n",
    "df['data_category'] = ''\n",
    "df['data_category_number'] = ''\n",
    "df = df.reindex(columns=['data_id', 'data_string', '2d_coor', 'data_title', 'data_category', 'data_category_number'])\n",
    "df.dropna()\n",
    "\n",
    "for index in range(len(df)):\n",
    "    pos=df.loc[index, \"data_title\"].find(\"rating: \")\n",
    "    #print(pos)\n",
    "   \n",
    "    #print(aaa)\n",
    "    df['data_category_number'][index]=df.loc[index, \"data_title\"][pos+8]\n",
    "    if df.loc[index, \"data_title\"][pos+8] == \"1\":\n",
    "        df['data_category'][index]=\"Poor\"\n",
    "    elif df.loc[index, \"data_title\"][pos+8] == \"2\":\n",
    "        df['data_category'][index]=\"Fair\"\n",
    "    elif df.loc[index, \"data_title\"][pos+8] == \"3\":\n",
    "        df['data_category'][index]=\"Good\"\n",
    "    elif df.loc[index, \"data_title\"][pos+8] == \"4\":\n",
    "        df['data_category'][index]=\"Very Good\"\n",
    "    elif df.loc[index, \"data_title\"][pos+8] == \"5\":\n",
    "        df['data_category'][index]=\"Excelent\"\n",
    "    df.loc[index, \"data_title\"]=df.loc[index, \"data_title\"][0:pos-2]\n",
    "df.head()\n",
    "\n",
    "df.to_csv('Care_Reviews_10k.csv', encoding='utf-8', index=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8700b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simpletransformers\n",
      "  Downloading simpletransformers-0.63.7-py3-none-any.whl (249 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.8/249.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting wandb>=0.10.32\n",
      "  Downloading wandb-0.13.2-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting streamlit\n",
      "  Downloading streamlit-1.12.2-py2.py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/ez/Desktop/projects/learningmachines_folder/venv/lib/python3.8/site-packages (from simpletransformers) (1.21.6)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m755.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-"
     ]
    }
   ],
   "source": [
    "!pip install simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "80b69a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.13.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: torch==1.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torchvision) (1.12.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torchvision) (4.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.9)\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97d67efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTextRepresentation: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTextRepresentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTextRepresentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15308\\1866943174.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['2d_coor'][idx]=sentenceVectors.tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15308\\1866943174.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['2d_coor'][idx]=word_embedding_avg.tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383\n",
      "1067\n",
      "1719\n",
      "1777\n",
      "1882\n",
      "3196\n",
      "4135\n",
      "4893\n",
      "5161\n",
      "5769\n",
      "6308\n",
      "6364\n",
      "6414\n",
      "6446\n",
      "6468\n",
      "6498\n",
      "6527\n",
      "6544\n",
      "6680\n",
      "8632\n",
      "9266\n",
      "10339\n",
      "10416\n",
      "11120\n",
      "11271\n",
      "12005\n",
      "12964\n",
      "13026\n",
      "13037\n",
      "13062\n",
      "13173\n",
      "13213\n",
      "13325\n",
      "13511\n",
      "13542\n",
      "14546\n",
      "15537\n",
      "16124\n",
      "16517\n",
      "16682\n",
      "16991\n",
      "17196\n",
      "17804\n",
      "18617\n",
      "18650\n",
      "18871\n",
      "19645\n",
      "19723\n",
      "19875\n",
      "19918\n",
      "19949\n",
      "19960\n",
      "19976\n",
      "19977\n",
      "20618\n",
      "20805\n",
      "21540\n",
      "22172\n",
      "22231\n",
      "25158\n",
      "25163\n",
      "25357\n",
      "25506\n",
      "26273\n",
      "26351\n",
      "26388\n",
      "26408\n",
      "26453\n",
      "26473\n",
      "26505\n",
      "26538\n",
      "26606\n",
      "27305\n",
      "30456\n",
      "31285\n",
      "31876\n",
      "31984\n",
      "32099\n",
      "32115\n",
      "32342\n",
      "32443\n",
      "32459\n",
      "33119\n",
      "33242\n",
      "33246\n",
      "33263\n",
      "33270\n",
      "33307\n",
      "33314\n"
     ]
    }
   ],
   "source": [
    "# Uses \"bert-base-uncased\" to get embeddings\n",
    "# For words more than 500, divides in chunks and gets average embeddings\n",
    "# Prints the rows were we have more than 500 words and averaging of embeddings needs to be done\n",
    "# Takes time to print on local GPU\n",
    "import transformers\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from simpletransformers.language_representation import RepresentationModel\n",
    "\n",
    "model=RepresentationModel(model_type=\"bert\", model_name=\"bert-base-uncased\", use_cuda=False)\n",
    "\n",
    "def updateDataFrame2(csv_file_name='Care_review_full.csv', model_max_length=500):\n",
    "    import pandas as pd\n",
    "    data = pd.read_csv(csv_file_name)\n",
    "    data=data.astype({'2d_coor': 'object'})\n",
    "    \n",
    "    def split_sentences(list_of_words):\n",
    "        chunked_list = list()\n",
    "        chunk_size = model_max_length\n",
    "        for i in range(0, len(list_of_words), chunk_size):\n",
    "            chunked_list.append(list_of_words[i:i+chunk_size])\n",
    "\n",
    "        return(chunked_list)\n",
    "\n",
    "    for idx in range(len(data['data_string'])):\n",
    "        chunkedListWithSent=[]\n",
    "        sent=\"\"\n",
    "    \n",
    "        if len(str(data['data_string'][idx]).split()) > 500:\n",
    "            tempString = data['data_string'][idx]\n",
    "            tempStringSplit = tempString.split()\n",
    "            chunkedLists = split_sentences(tempStringSplit)\n",
    "            \n",
    "            for sentenceList in chunkedLists:\n",
    "                sent=\" \".join(sentenceList)\n",
    "                chunkedListWithSent.append(sent)\n",
    "                sent=\"\"\n",
    "             \n",
    "            sentenceVectors = model.encode_sentences(chunkedListWithSent, combine_strategy=\"mean\")\n",
    "            word_embedding_avg = np.mean(sentenceVectors, axis=0)\n",
    "\n",
    "            print(idx)\n",
    "            data['2d_coor'][idx]=word_embedding_avg.tolist()\n",
    "\n",
    "        else:\n",
    "            tempString = data['data_string'][idx]\n",
    "            sentenceVectors = model.encode_sentences([tempString], combine_strategy=\"mean\")\n",
    "            data['2d_coor'][idx]=sentenceVectors.tolist()\n",
    "            \n",
    "    return data\n",
    "\n",
    "dataFrame=updateDataFrame2()\n",
    "dataFrame.to_csv(\"submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e681fd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTextRepresentation: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForTextRepresentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTextRepresentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_17364\\2452095990.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['2d_coor'][idx]=sentenceVectors.tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_17364\\2452095990.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['2d_coor'][idx]=word_embedding_avg.tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383\n",
      "                                  data_id  \\\n",
      "0    a224545f-1a07-47eb-96ee-a0d0cab23100   \n",
      "1    01a8cfc8-e207-4c72-a9fa-fa6353fde529   \n",
      "2    1a4fb4a6-6c56-4610-a151-b4b25a774cc8   \n",
      "3    9356a4fd-54fd-4604-a6a8-2d3067eba7cc   \n",
      "4    77526eed-5ff3-4f2f-80ce-da1048137cf4   \n",
      "..                                    ...   \n",
      "495  4ab54e0d-a655-489d-8de6-0fadffe72fef   \n",
      "496  f6578787-c6ea-432c-9a45-26c91a923bc2   \n",
      "497  983efbd4-88d3-49d5-896b-77d995b68e32   \n",
      "498  f4374484-6700-4d38-9c9d-1801258d38af   \n",
      "499  c82129a4-3c7a-4f75-9b15-797e6b59cc26   \n",
      "\n",
      "                                           data_string  \\\n",
      "0                                  Good place to visit   \n",
      "1    Went here for a swollen Jaw. Even though I was...   \n",
      "2    I was seen relatively quickly and the staff wa...   \n",
      "3    Reception and service couldn't have been more ...   \n",
      "4    I came in they were very busy the receptionist...   \n",
      "..                                                 ...   \n",
      "495  Staff is vey friendly and prompt with service ...   \n",
      "496  Great staff! Very friendly, took me back extre...   \n",
      "497  I was treated a couple of weeks ago by Dr. Hol...   \n",
      "498  Took my daughter in for a spider bite that loo...   \n",
      "499  Awful awful awful experience. Went in at 9, ve...   \n",
      "\n",
      "                                               2d_coor  \\\n",
      "0    [[0.23429743945598602, 0.3045189380645752, 0.1...   \n",
      "1    [[-0.28433531522750854, 0.06411413848400116, 0...   \n",
      "2    [[-0.28503552079200745, 0.06362159550189972, 0...   \n",
      "3    [[-0.024238204583525658, 0.022654889151453972,...   \n",
      "4    [[0.011776627041399479, 0.057415809482336044, ...   \n",
      "..                                                 ...   \n",
      "495  [[-0.19085608422756195, 0.02804723009467125, 0...   \n",
      "496  [[-0.1007789820432663, 0.06224357336759567, 0....   \n",
      "497  [[-0.08699473738670349, 0.26117026805877686, 0...   \n",
      "498  [[-0.10074206441640854, -0.0341695100069046, 0...   \n",
      "499  [[0.08840814977884293, 0.054697874933481216, 0...   \n",
      "\n",
      "                                            data_title data_category  \\\n",
      "0    urgentCare: Access Urgent Medical Care Pickeri...     Very Good   \n",
      "1    urgentCare: Access Urgent Medical Care Pickeri...          Poor   \n",
      "2    urgentCare: Access Urgent Medical Care Pickeri...      Excelent   \n",
      "3    urgentCare: Access Urgent Medical Care Pickeri...      Excelent   \n",
      "4    urgentCare: Access Urgent Medical Care Pickeri...      Excelent   \n",
      "..                                                 ...           ...   \n",
      "495            urgentCare: Doctors' Urgent Care Office     Very Good   \n",
      "496            urgentCare: Doctors' Urgent Care Office      Excelent   \n",
      "497            urgentCare: Doctors' Urgent Care Office      Excelent   \n",
      "498            urgentCare: Doctors' Urgent Care Office          Poor   \n",
      "499            urgentCare: Doctors' Urgent Care Office          Poor   \n",
      "\n",
      "     data_category_number  \n",
      "0                       4  \n",
      "1                       1  \n",
      "2                       5  \n",
      "3                       5  \n",
      "4                       5  \n",
      "..                    ...  \n",
      "495                     4  \n",
      "496                     5  \n",
      "497                     5  \n",
      "498                     1  \n",
      "499                     1  \n",
      "\n",
      "[500 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Uses \"bert-base-uncased\" to get embeddings\n",
    "# For words more than 500, divides in chunks and gets average embeddings\n",
    "\n",
    "# Prints first 500 rows in dataframe\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from simpletransformers.language_representation import RepresentationModel\n",
    "\n",
    "model=RepresentationModel(model_type=\"bert\", model_name=\"bert-base-uncased\", use_cuda=False)\n",
    "\n",
    "def updateDataFrame2(csv_file_name='Care_review_full.csv', model_max_length=500):\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(csv_file_name)\n",
    "    data=df.head(500)\n",
    "    #data = data.drop(columns=['Unnamed: 0'])\n",
    "    data=data.astype({'2d_coor': 'object'})\n",
    "    #print(data.dtypes)\n",
    "    \n",
    "    def split_sentences(list_of_words):\n",
    "        chunked_list = list()\n",
    "        chunk_size = model_max_length\n",
    "        for i in range(0, len(list_of_words), chunk_size):\n",
    "            chunked_list.append(list_of_words[i:i+chunk_size])\n",
    "\n",
    "        return(chunked_list)\n",
    "\n",
    "    for idx in range(len(data['data_string'])):\n",
    "        chunkedListWithSent=[]\n",
    "        sent=\"\"\n",
    "\n",
    "    \n",
    "        if len(str(data['data_string'][idx]).split()) > 500:\n",
    "            tempString = data['data_string'][idx]\n",
    "            tempStringSplit = tempString.split()\n",
    "            chunkedLists = split_sentences(tempStringSplit)\n",
    "            \n",
    "            for sentenceList in chunkedLists:\n",
    "                sent=\" \".join(sentenceList)\n",
    "                chunkedListWithSent.append(sent)\n",
    "                sent=\"\"\n",
    "             \n",
    "            sentenceVectors = model.encode_sentences(chunkedListWithSent, combine_strategy=\"mean\")\n",
    "            word_embedding_avg = np.mean(sentenceVectors, axis=0)\n",
    "\n",
    "            data['2d_coor'][idx]=word_embedding_avg.tolist()\n",
    "\n",
    "        else:\n",
    "            tempString = data['data_string'][idx]\n",
    "            sentenceVectors = model.encode_sentences([tempString], combine_strategy=\"mean\")\n",
    "            data['2d_coor'][idx]=sentenceVectors.tolist()\n",
    "            \n",
    "    return data\n",
    "\n",
    "dataFrame=updateDataFrame2()\n",
    "print(dataFrame)\n",
    "dataFrame.to_csv(\"submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e7f45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc07d24e2f18896857f0b2a651fe84ba40ce7b297e58d8804a308c8039f752a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
